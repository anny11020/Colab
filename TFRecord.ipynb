{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anny11020/Colab/blob/main/TFRecord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVrT1BaiJNft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "da281033-51f3-4060-f146-1edc6f08c530"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO8HeBfqUu6g"
      },
      "source": [
        "import math\n",
        "def getDatafile(file_dir, train_size, val_size):\n",
        "    \"\"\"Get list of train, val, test image path and label Parameters: ----------- file_dir : str, file directory train_size : float, size of test set val_size : float, size of validation set Returns: -------- train_img : str, list of train image path train_labels : int, list of train label test_img : test_labels : val_img : val_labels : \"\"\"\n",
        "\n",
        "    # images path list\n",
        "    images_path = []\n",
        "    # os.walk 遍历文件夹下的所有文件，包括子文件夹下的文件\n",
        "    for root, sub_folders, files in os.walk(file_dir):\n",
        "        for name in files:\n",
        "          images_path.append(file_dir+root+'/'+name)\n",
        "\n",
        "    # labels，images path have label of image\n",
        "    labels = []\n",
        "    for image_path in images_path:\n",
        "      label = int(image_path.split('/')[-2]) # 将对应的label提取出来\n",
        "      labels.append(label)\n",
        "\n",
        "    # 先将图片路径和标签合并\n",
        "    temp = np.array([images_path, labels]).transpose()\n",
        "\n",
        "    # 提前随机打乱\n",
        "    np.random.shuffle(temp)\n",
        "\n",
        "\n",
        "    images_path_list = temp[0]    # image path\n",
        "    labels_list = temp[1]         # label\n",
        "\n",
        "\n",
        "\n",
        "    # train val test split\n",
        "    train_num = math.ceil(len(temp) * train_size)\n",
        "    print('train_num',train_num)\n",
        "    val_num = math.ceil(len(temp) * val_size)\n",
        "\n",
        "    # train img and labels\n",
        "    train_img = images_path_list[0:train_num]\n",
        "    train_labels = labels_list[0:train_num]\n",
        "    train_labels = [int(float(i)) for i in train_labels]\n",
        "\n",
        "    # val img and labels\n",
        "    val_img = images_path_list[train_num:train_num+val_num]\n",
        "    val_labels = labels_list[train_num:train_num+val_num]\n",
        "    val_labels = [int(float(i)) for i in val_labels]\n",
        "\n",
        "    # test img and labels\n",
        "    test_img = images_path_list[train_num+val_num:]\n",
        "    test_labels = labels_list[train_num+val_num:]\n",
        "    test_labels = [int(float(i)) for i in test_labels]\n",
        "\n",
        "    # 返回图片路径列表和对应标签列表\n",
        "    return train_img, train_labels, val_img, val_labels, test_img, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prFrfQPAVN_N"
      },
      "source": [
        "def _int64_feature(value):\n",
        "    \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
        "    if not isinstance(value, list):\n",
        "        value = [value]\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-mGtK4QVNye"
      },
      "source": [
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofA1PIo4VSoQ"
      },
      "source": [
        "def convert_to_TFRecord(images, labels, save_dir, name):\n",
        "    \"\"\"Convert images and labels to TFRecord file. Parameters: ----------- images : list of image path, string labels : list of labels, int save_dir : str, the directory to save TFRecord file name : str, the name of TFRecord file Returns: -------- no return \"\"\"\n",
        "\n",
        "    filename = os.path.join(save_dir, 'cache', name + '.tfrecords')\n",
        "    n_samples = len(labels)\n",
        "\n",
        "    if np.shape(images)[0] != n_samples:\n",
        "        raise ValueError('Images size {} does not match label size {}'.format(images.shape[0], n_samples))\n",
        "\n",
        "    writer = tf.python_io.TFRecordWriter(filename)       # TFRecordWriter class\n",
        "    print ('Convert to TFRecords...')\n",
        "    for i in xrange(0, n_samples):\n",
        "        try:\n",
        "            # 首先利用matplotlib读取图片，类型是np.ndarray(uint8)\n",
        "            image = plt.imread(images[i])                # type(image) must be array\n",
        "            image_raw = image.tobytes()                  # transform array to bytes\n",
        "            label = int(labels[i])\n",
        "            example = tf.train.Example(features=tf.train.Features(feature={\n",
        "                            'label': _int64_feature(label),\n",
        "                            'image_raw': _bytes_feature(image_raw)}))\n",
        "            writer.write(example.SerializeToString())\n",
        "        except IOError as e:\n",
        "            print ('Could not read:{}'.format(images[i]))\n",
        "            print ('Skip it!')\n",
        "    writer.close()\n",
        "    print ('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFGxbmZIXEM0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2a4c9aa-e794-4f10-a0dc-12d77002fd94"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/NEW/品御方/燕窩/Image/')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1  2  3  4  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OASAgKXNVnEf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "30902db5-92df-410b-ad7d-9d8e09434a30"
      },
      "source": [
        "# Main\n",
        "if __name__ == '__main__':\n",
        "    # figure dir\n",
        "    project_dir = os.getcwd()\n",
        "    # get list of images path and list of labels\n",
        "    train_img, train_labels, val_img, val_labels, test_img, test_labels = getDatafile(project_dir,\n",
        "                                                                                      train_size=0.7,\n",
        "                                                                                      val_size=0.15)\n",
        "    # convert TFRecord file\n",
        "    TFRecord_list = ['train', 'val', 'test']\n",
        "    img_labels_list = [[train_img, train_labels], [val_img, val_labels], [test_img, test_labels]]\n",
        "    save_dir = os.getcwd()\n",
        "    for index, TFRecord_name in enumerate(TFRecord_list):\n",
        "        convert_to_TFRecord(img_labels_list[index][0], img_labels_list[index][1],\n",
        "                            save_dir,\n",
        "                            TFRecord_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-13d93e25feed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     train_img, train_labels, val_img, val_labels, test_img, test_labels = getDatafile(project_dir,\n\u001b[1;32m      6\u001b[0m                                                                                       \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                                                       val_size=0.1)\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# convert TFRecord file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mTFRecord_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-dafb5cbe0736>\u001b[0m in \u001b[0;36mgetDatafile\u001b[0;34m(file_dir, train_size, val_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtrain_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_path_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# val img and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-dafb5cbe0736>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtrain_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_path_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# val img and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/content/drive/My Drive/NEW/品御方/燕窩/Image/content/drive/My Drive/NEW/品御方/燕窩/Image/4/Level4_58.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfS6TTrQW-m0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}