{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anny11020/Colab/blob/main/X%E5%85%89%E5%88%86%E9%A1%9E_VGG16_%E5%BB%BA%E7%BD%AE%E7%92%B0%E5%A2%83%2B%E8%A8%93%E7%B7%B4%2B%E5%84%B2%E5%AD%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhRDrO0KkaFk",
        "outputId": "648faa40-5a75-46c7-d735-ba4cb6e60fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import sys\n",
        "print(\"Python version\")\n",
        "print (sys.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version\n",
            "3.6.9 (default, Jul 17 2020, 12:50:27) \n",
            "[GCC 8.4.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3MUG7kOsMhD"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "LR = 0.001\n",
        "STEP_SIZE = 5\n",
        "GAMMA = 0.1\n",
        "#LR = 1e-1\n",
        "EPOCH = 100\n",
        "VAL_SPLIT = 0.25\n",
        "#NUM_CORES = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIGxqqTDr3KA"
      },
      "source": [
        "SAVE_PATH = '/content/drive/My Drive/Colab Notebooks/Pytorch/Classify/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s2z3MhpA21X",
        "outputId": "de6a63ef-3293-49f1-fa5b-0dbd833ffcdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import datetime\n",
        "today = datetime.date.today()\n",
        "print(today)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd0N6aWMEELL"
      },
      "source": [
        "# 使用TPU\n",
        "1. https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb#scrollTo=3P6b3uqfzpDI\n",
        "2. https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb?hl=zh-cn\n",
        "3. https://github.com/pytorch/xla/tree/master/contrib/colab\n",
        "4. https://pytorch-lightning.readthedocs.io/en/0.7.1/tpu.html\n",
        "5. https://zhuanlan.zhihu.com/p/88931693"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVD4Ms3qBtWw"
      },
      "source": [
        "\"\"\"\n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXA52VQvESAT",
        "outputId": "3461089b-24ad-4002-bb64-cedd26377190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "#!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.6-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cloud-tpu-client==0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting torch-xla==1.6\n",
            "\u001b[?25l  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.6-cp36-cp36m-linux_x86_64.whl (133.2MB)\n",
            "\u001b[K     |████████████████████████████████| 133.2MB 89kB/s \n",
            "\u001b[?25hCollecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (50.3.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.52.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.6.20)\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client, torch-xla\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0 torch-xla-1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn1kgdFLEVsC",
        "outputId": "b57b7de5-3a78-4bf7-8b8b-a33a9f2c8f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\"\"\"\n",
        "# imports the torch_xla package\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.6...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.6...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.6...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.6\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pchUNRwHtBCY"
      },
      "source": [
        "# 安裝 pytorch\n",
        " * 最新\n",
        "  - https://pytorch.org/get-started/locally/\n",
        "  - pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch. org/whl/torch_stable.html\n",
        "  - pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        " * 1.0.0\n",
        "  - pip install torch==1.0.0 torchvision==0.2.1\n",
        "  - pip install Pillow==6.1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffCCYXFxsa4C",
        "outputId": "a1ca401d-f14c-4c9e-8150-7ed4b6aab173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.6.0+cu101 in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision==0.7.0+cu101 in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERx3EWA2s5h3",
        "outputId": "752386e5-ad53-4607-c9bc-8c1d19010a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9VIyWBpqO61"
      },
      "source": [
        "# 資料載入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvZDWdWiZ6ko"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms, utils, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXBrIoHRgAo_"
      },
      "source": [
        "* 參考資料\n",
        "  1. https://www.cnblogs.com/denny402/p/7512516.html\n",
        "  2. https://blog.csdn.net/TH_NUM/article/details/80877435\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ZCu2q0Z688",
        "outputId": "b1ca4340-ce6a-4a46-dc5f-3618d867e00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "img_data = torchvision.datasets.ImageFolder('/content/drive/My Drive/NEW/NTUST/醫療Dataset/5839_18613_bundle_archive',\n",
        "                        transform = transforms.Compose([\n",
        "                        transforms.Resize(256),\n",
        "                        transforms.CenterCrop(224),\n",
        "                        #transforms.RandomHorizontalFlip(),\n",
        "                        transforms.ToTensor()])\n",
        "                        )\n",
        "print(img_data.class_to_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'images_001': 0, 'images_002': 1, 'images_003': 2, 'images_004': 3, 'images_005': 4, 'images_006': 5, 'images_007': 6, 'images_008': 7, 'images_009': 8, 'images_010': 9, 'images_011': 10, 'images_012': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omCba8VKfMM4",
        "outputId": "f5549bee-4cca-4896-951f-77c10382ca40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(img_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ2Ls39iJq-H"
      },
      "source": [
        "# 資料處理 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0uLUlfyJAC5",
        "outputId": "e9fa7c9e-7b3b-47a2-c2a1-ab2b4c00332d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"\n",
        "data_loader = torch.utils.data.DataLoader(img_data, batch_size=BATCH_SIZE,shuffle=True)\n",
        "print(len(data_loader))\n",
        "4606\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndata_loader = torch.utils.data.DataLoader(img_data, batch_size=BATCH_SIZE,shuffle=True)\\nprint(len(data_loader))\\n4606\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMW0xo0TaAai",
        "outputId": "280bb81f-71e3-4258-fbdf-802b7a8264ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\"\"\"\n",
        "def show_batch(imgs):\n",
        "    grid = utils.make_grid(imgs,nrow=5)\n",
        "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "    plt.title('Batch from dataloader')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef show_batch(imgs):\\n    grid = utils.make_grid(imgs,nrow=5)\\n    plt.imshow(grid.numpy().transpose((1, 2, 0)))\\n    plt.title('Batch from dataloader')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQPd4Cm9Z6_b",
        "outputId": "3b6e1990-a990-418c-b621-173186a53f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\"\"\"\n",
        "for i, (batch_x, batch_y) in enumerate(data_loader):\n",
        "    if i<4:\n",
        "        print(i, batch_x.size(), batch_y.size())\n",
        "\n",
        "        show_batch(batch_x)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    else:\n",
        "      break\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfor i, (batch_x, batch_y) in enumerate(data_loader):\\n    if i<4:\\n        print(i, batch_x.size(), batch_y.size())\\n\\n        show_batch(batch_x)\\n        plt.axis('off')\\n        plt.show()\\n    else:\\n      break\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPh7vFG7ggWF",
        "outputId": "43d45283-cc56-4792-9aaf-bfc97bb6c7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"\n",
        "#没有任何转变，所有返回的还是PIL Image对象\n",
        "print(img_data[0][1]) #第二维度为1 ，表示label\n",
        "print(img_data[0][0]) #第二维度为0，表示图片数据\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#没有任何转变，所有返回的还是PIL Image对象\\nprint(img_data[0][1]) #第二维度为1 ，表示label\\nprint(img_data[0][0]) #第二维度为0，表示图片数据\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8uQ6xhwJuqD"
      },
      "source": [
        "# 資料處理 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z40jWXUlF9Yl"
      },
      "source": [
        "* SPLIT DATA -\n",
        "TRAIN VALID TEST\n",
        "https://discuss.pytorch.org/t/how-to-split-dataset-into-test-and-validation-sets/33987/5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG64fmP9HLFb"
      },
      "source": [
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw8vWKSNIjvj"
      },
      "source": [
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "    return datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6vdZAHFHlBO",
        "outputId": "e1599855-5887-4c29-9a82-4ba74f08d941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "datasets = train_val_dataset(img_data,VAL_SPLIT)\n",
        "print(len(datasets['train']))\n",
        "print(len(datasets['val']))\n",
        "# The original dataset is available in the Subset class\n",
        "print(datasets['train'].dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61590\n",
            "20530\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 82120\n",
            "    Root location: /content/drive/My Drive/NEW/NTUST/醫療Dataset/5839_18613_bundle_archive\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
            "               CenterCrop(size=(224, 224))\n",
            "               ToTensor()\n",
            "           )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Jl6ldnIK3B",
        "outputId": "987de306-55f5-4ea3-d096-36d319a2adbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataloaders = {x:torch.utils.data.DataLoader(datasets[x],BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train','val']}\n",
        "x,y = next(iter(dataloaders['train']))\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5H6NwOKqTF1"
      },
      "source": [
        "# VGG MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwu2Twefh2y7"
      },
      "source": [
        "* VGG訓練\n",
        "https://hackmd.io/@lido2370/HyLTOlSn4?type=view"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ROAikHFh-Qh",
        "outputId": "cd312e39-8d1e-45e7-99fa-af9c1c828481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        }
      },
      "source": [
        "vgg16 = models.vgg16(pretrained=True)\n",
        "vgg16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91bukoCEi58w"
      },
      "source": [
        "# Freeze parameters so we don't backprop through them\n",
        "for param in vgg16.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnoVNX5LHJzK"
      },
      "source": [
        "PYTORCH ON XLA DEVICES\n",
        "1. http://pytorch.org/xla/release/1.6/index.html\n",
        "2. https://zhuanlan.zhihu.com/p/\n",
        "3. https://www.kaggle.com/piantic/pytorch-tpu\n",
        "4. https://pytorch.org/xla/release/1.6/index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvgv7tR6i_97",
        "outputId": "1f9d3803-bd1a-4bdf-cb4d-ef5963452241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\n",
        "# fine tune the last classifier layer from 1000 to 12 dim(num. of classifier).\n",
        "# fine tune 最後一層分類數目從 1000 修改成 12。\n",
        "vgg16.classifier[6] = torch.nn.Linear(4096,12)\n",
        "vgg16 = vgg16.cuda() #use GPU\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# fine tune the last classifier layer from 1000 to 12 dim(num. of classifier).\\n# fine tune 最後一層分類數目從 1000 修改成 12。\\nvgg16.classifier[6] = torch.nn.Linear(4096,12)\\nvgg16 = vgg16.cuda() #use GPU\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLLzZtZYjFIB",
        "outputId": "f72a6a61-5509-4ecc-db5a-3bd90cfc18a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "# 將 VGG16 model 打印出來\n",
        "from torchsummary import summary\n",
        "summary(vgg16.cuda(), (3, 224, 224))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# 將 VGG16 model 打印出來\\nfrom torchsummary import summary\\nsummary(vgg16.cuda(), (3, 224, 224))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAAHiOxaJc3U"
      },
      "source": [
        "# fine tune the last classifier layer from 1000 to 12 dim(num. of classifier).\n",
        "# fine tune 最後一層分類數目從 1000 修改成 12。\n",
        "vgg16.classifier[6] = torch.nn.Linear(4096,12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgk6IhinNRX5",
        "outputId": "d1fcb453-619a-4a6a-8242-f637b9dafbc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"\n",
        "devices = xm.xla_device()\n",
        "#devices =(xm.get_xla_supported_devices(max_devices=NUM_CORES) if NUM_CORES != 0 else [])\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "print(\"Devices: {}\".format(devices))\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Devices: xla:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBrlgVPIbdUa"
      },
      "source": [
        "#import torch_xla.distributed.data_parallel as dp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3uiAJ-5bXC9",
        "outputId": "1791d717-e509-40a5-e0b2-cd78a2e8a9a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\"\"\"\n",
        "# Scale learning rate to num cores\n",
        "learning_rate = LR * max(len(devices), 1)\n",
        "# Pass [] as device_ids to run using the PyTorch/CPU engine.\n",
        "model = dp.DataParallel(vgg16, device_ids=devices)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Scale learning rate to num cores\\nlearning_rate = LR * max(len(devices), 1)\\n# Pass [] as device_ids to run using the PyTorch/CPU engine.\\nmodel = dp.DataParallel(vgg16, device_ids=devices)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9GMLa6gJ-nD"
      },
      "source": [
        "\"\"\"\n",
        "# 使用TPU\n",
        "vgg16 = vgg16.to(devices)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDLfZiflqXgB"
      },
      "source": [
        "# TRAIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHVYseV1mLi8"
      },
      "source": [
        "* TRAIN MODEL\n",
        "https://zhuanlan.zhihu.com/p/39455807"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnQ-UTz_lNbV"
      },
      "source": [
        "model = vgg16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCBqQmzgzVEv"
      },
      "source": [
        "* scheduler\n",
        "https://zhuanlan.zhihu.com/p/69411064"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cv6pTZujSrl"
      },
      "source": [
        "# 選擇優化器 & loss function\n",
        "#optimizer = torch.optim.Adam(vgg16.parameters(), lr=LR)   # optimize all cnn parameters\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=LR, alpha=0.9)\n",
        "loss_func = torch.nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, STEP_SIZE, gamma=GAMMA, last_epoch=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL-WPt5KkPjE"
      },
      "source": [
        "* 訓練模型\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYJMwTF0ygqB",
        "outputId": "b941fcb0-8fe1-4c90-88f2-201c7acdb9f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-v4rhepyc3H"
      },
      "source": [
        "from tensorboardX import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efA2RfF3KaTZ"
      },
      "source": [
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQvm4N0E_Cta"
      },
      "source": [
        "#進度條"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWdWp6M6AEXC"
      },
      "source": [
        "* 進度條用法\n",
        "https://kknews.cc/zh-tw/code/2y6jbx9.html\n",
        "  1. 在使用tqdm顯示進度條的時候，如果代碼中存在print可能會導致輸出多行進度條，此時可以將print語句改為tqdm.write\n",
        "  https://blog.csdn.net/kdongyi/article/details/101547216\n",
        "  2. python tqdm模塊不能單行顯示問題\n",
        "  https://blog.csdn.net/weixin_42138078/article/details/81215207"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHkNVlnR7qZ-"
      },
      "source": [
        "#from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMkADdqF6u1C"
      },
      "source": [
        "* Progressbar\n",
        " - https://stackoverrun.com/cn/q/10682996\n",
        " - https://blog.csdn.net/dcrmg/article/details/79525167"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkOAlibW8FxR"
      },
      "source": [
        "#pip install progressbar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPf94Tqn7IrW",
        "outputId": "042f6bd8-8895-463a-b536-fca87c060eee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "from progressbar import *\n",
        "\n",
        "widgets = ['Progress: ',Percentage(), ' ', Bar('#'),' ', Timer(),' ', ETA(), ' ', FileTransferSpeed()]\n",
        "# pbar = ProgressBar(widgets=widgets, maxval=10*total).start()\n",
        "# pbar.update(10 * i + 1)\n",
        "# pbar.finish()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom progressbar import *\\n\\nwidgets = ['Progress: ',Percentage(), ' ', Bar('#'),' ', Timer(),' ', ETA(), ' ', FileTransferSpeed()]\\n# pbar = ProgressBar(widgets=widgets, maxval=10*total).start()\\n# pbar.update(10 * i + 1)\\n# pbar.finish()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5rLUebA_QEV"
      },
      "source": [
        "# 在使用本方法之前，请先做如下import\n",
        "from __future__ import division\n",
        "import math\n",
        "import sys\n",
        "\n",
        "def progressbar(cur, total):\n",
        "    percent = '{:.2%}'.format(cur / total)\n",
        "    sys.stdout.write('\\r')\n",
        "    sys.stdout.write(\"[%-50s] %s\" % ('=' * int(math.floor(cur * 50 / total)),percent))\n",
        "    sys.stdout.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPGzTh4V_ICY"
      },
      "source": [
        "#運算"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHELBlB_MjTF"
      },
      "source": [
        "[batch_size, channels, height, width]\n",
        "* 錯誤\n",
        "  1. LABEL CUDA\n",
        "  https://discuss.pytorch.org/t/attributeerror-int-object-has-no-attribute-cuda/30150/2\n",
        "  2. INPUT SIZE\n",
        "  https://blog.csdn.net/weixin_38208741/article/details/97894292\n",
        "  https://stackoverflow.com/questions/57237381/runtimeerror-expected-4-dimensional-input-for-4-dimensional-weight-32-3-3-but\n",
        "  3. SQUEEZE\n",
        "  https://blog.csdn.net/xiexu911/article/details/80820028\n",
        "\n",
        "* 解決\n",
        "  1. input unsqueeze\n",
        "  2. label unsqueeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0epayha-9Gy"
      },
      "source": [
        "CUT = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlvs7EUQthdD"
      },
      "source": [
        "running_loss = 0.0\n",
        "running_corrects = 0.0\n",
        "data_count = 0\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "        global running_loss\n",
        "        global running_corrects\n",
        "        global data_count\n",
        "        # TPU\n",
        "        model.to(dev)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print('\\n\\n----- Epoch {}/{} -----\\n'.format(epoch, num_epochs - 1))\n",
        "            for phase in ['train', 'val']:\n",
        "\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "                    model.train(True)\n",
        "                else:\n",
        "                    model.train(False)\n",
        "                    running_loss = 0.0\n",
        "                    running_corrects = 0.0\n",
        "\n",
        "                RUN_TOTAL = int(len(datasets[phase]) / CUT)\n",
        "\n",
        "                for data in datasets[phase]:\n",
        "                  progressbar(data_count,RUN_TOTAL)\n",
        "                  if data_count >= RUN_TOTAL:\n",
        "                    data_count = 0\n",
        "                    break\n",
        "\n",
        "                  inputs, labels = data\n",
        "                  \"\"\"\n",
        "                  # TPU\n",
        "                  inputs = Variable(inputs.to(dev))\n",
        "                  inputs = inputs.unsqueeze(0)\n",
        "                  labels = torch.tensor(labels)\n",
        "                  labels = labels.unsqueeze(0)\n",
        "                  labels = Variable(labels.to(dev))\n",
        "                  \"\"\"\n",
        "\n",
        "                  # GPU\n",
        "                  if torch.cuda.is_available():\n",
        "                      #inputs = Variable(inputs.cuda())\n",
        "                      inputs = Variable(inputs.to(dev))\n",
        "                      inputs = inputs.unsqueeze(0)\n",
        "                      labels = torch.tensor(labels)\n",
        "                      labels = labels.unsqueeze(0)\n",
        "                      #labels = Variable(labels.cuda())\n",
        "                      labels = Variable(labels.to(dev))\n",
        "                  else:\n",
        "                      inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "\n",
        "                  optimizer.zero_grad()\n",
        "\n",
        "                  outputs = model(inputs)\n",
        "                  #outputs = model(inputs.permute(1,0,2,3))\n",
        "                  #outputs = model(inputs[None,...])\n",
        "\n",
        "                  _, preds = torch.max(outputs.data, 1)\n",
        "                  loss = criterion(outputs, labels)\n",
        "                  if phase == 'train':\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "                      #xm.optimizer_step(optimizer, barrier=True)\n",
        "\n",
        "                  running_loss += loss.data.item()\n",
        "                  running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "                  data_count += 1\n",
        "\n",
        "                epoch_loss = running_loss / RUN_TOTAL\n",
        "                epoch_acc = running_corrects / RUN_TOTAL\n",
        "\n",
        "                if phase == 'train':\n",
        "                    writer.add_scalar('data/trainloss', epoch_loss, epoch)\n",
        "                    writer.add_scalar('data/trainacc', epoch_acc, epoch)\n",
        "                else:\n",
        "                    writer.add_scalar('data/valloss', epoch_loss, epoch)\n",
        "                    writer.add_scalar('data/valacc', epoch_acc, epoch)\n",
        "\n",
        "                print('\\n{} - Loss: {:.4f} Acc: {:.4f}\\n'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "                save_name = SAVE_PATH+'/CheckPoint_'+str(today)+'_'+str(epoch)+'.pth'\n",
        "                torch.save({'epoch': epoch,\n",
        "                      'model_state_dict': model.state_dict(),\n",
        "                      'optimizer_state_dict': optimizer.state_dict(),\n",
        "                      'loss': epoch_loss,}, save_name)\n",
        "\n",
        "                \"\"\"\n",
        "                save_name_output = SAVE_PATH+'/output_'+today+'_'+epoch+'.pth'\n",
        "                torch.save(output, save_name_output)\n",
        "                save_name_model = SAVE_PATH+'/model_'+today+'_'+epoch+'.pth'\n",
        "                torch.save(model, save_name_model)\n",
        "                \"\"\"\n",
        "\n",
        "        writer.export_scalars_to_json(SAVE_PATH+\"/all_scalars.json\")\n",
        "        writer.close()\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA4NlwGqAp36",
        "outputId": "13cfe55d-ff14-46b7-99e7-06c03e6c3458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#載入先前資料\n",
        "\n",
        "save_file = SAVE_PATH+\"/2020-10-18/CheckPoint_2020-10-18_24.pth\"\n",
        "checkpoint = torch.load(save_file)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "print('epoch: ',epoch)\n",
        "print('loss: ',loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  24\n",
            "loss:  43.43054459778577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqb7FEBEyp1V",
        "outputId": "4d90f5ba-d4e0-4937-cc63-d5c960a72a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "output = train_model(model,loss_func,optimizer,scheduler,EPOCH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "----- Epoch 0/99 -----\n",
            "\n",
            "\r[                                                  ] 0.00%"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[=                                                 ] 2.31%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA1urT-zz9Er"
      },
      "source": [
        "torch.save(output, SAVE_PATH+'/model_'+str(today).pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io1joCVdA25B"
      },
      "source": [
        "# LOAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEhTdB_cA6Iz"
      },
      "source": [
        "CHECK POINT\n",
        "https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5-XXB4A546"
      },
      "source": [
        "\"\"\"\n",
        "model = Net()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "model.train()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKbvDo4hBAoz"
      },
      "source": [
        "MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_VvkPpe58Jm"
      },
      "source": [
        "#model = torch.load(SAVE_PATH+'./model_20201016.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}